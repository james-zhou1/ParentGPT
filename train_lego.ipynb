{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is designed to test the hypothesis that the order of data can significantly impact the speed at which a neural network training converges. \n",
    "\n",
    "We will be using a simple task of adding integers for this experiment. This task is chosen as it will take less time to train the model.\n",
    "\n",
    "We will experiment with various data orderings. These include multiple random orderings, and datapoints ranked by GPT 3.5 with respect to the perceived difficulty level of the datapoint. \n",
    "\n",
    "In addition, we will also explore a scenario where we construct a hypothetical skill tree required to achieve a low loss on the dataset. The datapoints will then be sorted according to a topological sort of the skills involved. \n",
    "\n",
    "Let's begin by importing the necessary libraries and loading the GPT2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' gamears su 0 years saithper��']\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "from torchtyping import TensorType\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# Example usage:\n",
    "input_tensor = torch.randint(0, 1000, (1, 10))  # Random tensor for testing. Dimensions represent [batch_size, sequence_length]\n",
    "output = model(input_tensor)  # Output tensor from the GPT2 model. Dimensions represent [batch_size, sequence_length, hidden_state]\n",
    "token_ids = input_tensor.tolist()\n",
    "# Decode the token ids to tokens using batch decode\n",
    "decoded_output = tokenizer.batch_decode(token_ids, skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a: tensor([[321],\n",
      "        [571]])\n",
      "Input b: tensor([[654],\n",
      "        [429]])\n",
      "Sum: tensor([[ 975],\n",
      "        [1000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a custom dataset for integer addition\n",
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, num_samples: int, max_integer: int):\n",
    "        self.num_samples = num_samples\n",
    "        self.max_integer = max_integer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a = torch.randint(0, self.max_integer, (1,))\n",
    "        b = torch.randint(0, self.max_integer, (1,))\n",
    "        sum_ab = a + b\n",
    "        return a, b, sum_ab\n",
    "\n",
    "# Create a dataloader\n",
    "num_samples = 10000\n",
    "max_integer = 1000\n",
    "batch_size = 2\n",
    "addition_dataset = AdditionDataset(num_samples, max_integer)\n",
    "addition_dataloader = DataLoader(addition_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Test the dataloader\n",
    "data_iter = iter(addition_dataloader)\n",
    "data = next(data_iter)\n",
    "print(f\"Input a: {data[0]}\")\n",
    "print(f\"Input b: {data[1]}\")\n",
    "print(f\"Sum: {data[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wte.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomic tokens: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '²', '³', '¹', '00', '01', '000', '10', '12', '50', '19', '11', '20', '201', '30', '15', '14', '16', '13', '25', '18', '17', '24', '80', '40', '22', '60', '23', '29', '27', '26', '28', '99', '33', '70', '200', '45', '35', '0000', '64', '75', '21', '38', '44', '36', '32', '39', '34', '05', '37', '48', '66', '55', '47', '08', '49', '09', '65', '07', '02', '04', '100', '03', '68', '31', '67', '59', '06', '77', '58', '69', '88', '46', '57', '43', '42', '78', '79', '90', '95', '41', '56', '54', '500', '98', '76', '52', '53', '51', '86', '74', '89', '2015', '72', '73', '96', '71', '2014', '63', '62', '2016', '85', '61', '2017', '97', '84', '87', '94', '92', '83', '93', '300', '2013', '91', '82', '81', '2012', '400', '800', '2018', '600', '00000000', '001', '150', '101', '250', '2011', '700', '123', '120', '2010', '2009', '000000', '2000', '003', '110', '2008', '125', '256', '429', '2007', '128', '1000', '900', '130', '2006', '105', '255', '104', '160', '2005', '109', '2001', '168', '112', '350', '140', '103', '180', '360', '115', '102', '750', '108', '2004', '106', '107', '2003', '240', '111', '119', '114', '113', '127', '118', '2002', '133', '999', '135', '170', '175', '124', '192', '650', '220', '117', '152', '450', '0001', '225', '148', '116', '122', '144', '157', '204', '129', '155', '145', '264', '301', '1999', '202', '6666', '199', '230', '121', '126', '149', '320', '159', '137', '190', '134', '1990', '132', '138', '370', '147', '139', '270', '188', '333', '00000', '306', '216', '136', '010', '146', '165', '280', '1998', '143', '205', '158', '304', '208', '153', '308', '1997', '154', '210', '156', '002', '249', '185', '260', '386', '179', '212', '401', '211', '1995', '167', '131', '223', '206', '480', '169', '195', '1996', '214', '375', '198', '235', '177', '203', '305', '005', '209', '303', '299', '1994', '302', '550', '207', '252', '384', '184', '194', '004', '265', '174', '245', '307', '248', '166', '222', '178', '275', '164', '2019', '215', '189', '187', '239', '229', '340', '172', '1980', '238', '142', '380', '247', '141', '228', '1992', '720', '3000', '707', '1080', '176', '163', '224', '9999', '182', '151', '232', '290', '227', '234', '1993', '1991', '217', '0000000', '467', '237', '365', '183', '3333', '226', '236', '193', '254', '197', '268', '162', '186', '015', '259', '008', '288', '196', '173', '233', '1989', '266', '258', '440', '0000000000000000', '231', '267', '244', '295', '850', '007', '512', '313', '278', '161', '390', '393', '279', '330', '221', '408', '1111', '269', '285', '213', '404', '191', '377', '297', '325', '405', '243', '625', '1988', '310', '364', '309', '246', '277', '286', '016', '181', '296', '171', '385', '420', '446', '357', '1987', '666', '335', '273', '349', '368', '1200', '4000', '5000', '289', '294', '345', '646', '298', '470', '287', '367', '242', '315', '1016', '312', '276', '888', '006', '1986', '251', '805', '1984', '499', '808', '338', '011', '355', '253', '014', '050', '257', '608', '009', '218', '399', '274', '241', '219', '667', '271', '348', '509', '478', '379', '1985', '262', '765', '018', '644', '336', '456', '1983', '017', '777', '458', '409', '263', '339', '406', '389', '586', '272', '630', '261', '407', '012', '444', '013', '283', '284', '281', '388', '019', '455', '346', '768', '378', '359', '1982', '369', '802', '678', '1970', '347', '395', '374', '950', '555', '640', '448', '358', '520', '875', '334', '602', '709', '337', '490', '403', '342', '505', '293', '331', '479', '609', '430', '449', '604', '503', '398', '607', '767', '356', '425', '343', '376', '332', '354', '978', '387', '392', '605', '366', '402', '282', '475', '708', '323', '485', '292', '704', '477', '457', '508', '080', '606', '410', '649', '353', '397', '352', '316', '995', '459', '200000', '344', '501', '291', '504', '1979', '020', '314', '488', '341', '510', '1500', '495', '686', '324', '8000', '647', '396', '317', '560', '484', '990', '327', '0002', '454', '486', '328', '648', '2200', '688', '775', '809', '394', '460', '383', '373', '705', '998', '447', '443', '540', '415', '595', '502', '487', '319', '361', '416', '351', '507', '706', '1981', '476', '363', '1024', '911', '506', '603', '362', '668', '690', '489', '655', '685', '318', '804', '1600', '575', '382', '311', '498', '451', '659', '321', '00200000', '453', '381', '025', '669', '040', '702', '372', '703', '665', '807', '590', '920', '0010', '322', '414', '695', '680', '576', '656', '679', '657', '784', '391', '452', '496', '790', '1977', '473', '052', '472', '556', '1978', '329', '806', '371', '497', '1976', '755', '696', '756', '759', '471', '463', '1969', '658', '1975', '468', '1960', '417', '996', '758', '559', '530', '474', '483', '969', '620', '585', '578', '968', '525', '030', '0100', '654', '588', '889', '610', '1800', '326', '412', '757', '570', '960', '580', '698', '662', '494', '442', '776', '864', '997', '418', '441', '778', '660', '687', '462', '980', '697', '435', '424', '482', '428', '677', '810', '1973', '915', '492', '481', '045', '884', '779', '789', '1027', '552', '1920', '558', '689', '651', '461', '840', '760', '1974', '024', '780', '787', '1972', '796', '785', '1971', '491', '642', '598', '060', '801', '795', '992', '684', '701', '511', '880', '601', '579', '820', '643', '770', '754', '1945', '557', '66666666', '465', '1100', '433', '466', '411', '866', '1968', '985', '2020', '427', '675', '989', '090', '676', '994', '975', '1950', '7601', '641', '426', '877', '1967', '571', '70710', '469', '882', '493', '710', '652', '910', '597', '798', '437', '423', '6000', '599', '445', '070', '057', '803', '772', '970', '612', '031', '752', '436', '551', '438', '670', '672', '730', '562', '682', '044', '518', '022', '899', '413', '589', '987', '616', '035', '554', '1966', '885', '1007', '422', '033', '535', '536', '753', '464', '0200', '587', '797', '909', '2500', '027', '793', '00007', '993', '905', '549', '886', '533', '860', '419', '725', '626', '1963', '694', '1965', '023', '545', '432', '674', '1959', '930', '855', '046', '799', '740', '718', '714', '596', '673', '663', '592', '515', '026', '582', '537', '583', '671', '786', '925', '584', '075', '653', '594', '1964', '782', '088', '563', '692', '421', '887', '059', '771', '901', '021', '614', '773', '623', '940', '574', '870', '028', '615', '434', '439', '661', '048', '699', '825', '565', '514', '618', '516', '613', '683', '544', '774', '1001', '727', '519', '055', '561', '20439', '617', '047', '524', '553', '1900', '792', '517', '762', '628', '748', '635', '083', '830', '751', '954', '728', '76561', '693', '526', '729', '681', '949', '036', '629', '581', '833', '573', '513', '896', '572', '043', '747', '029', '916', '591', '593', '986', '736', '568', '952', '645', '883', '528', '089', '10000', '577', '546', '815', '712', '691', '522', '538', '763', '953', '893', '781', '529', '523', '034', '627', '548', '032', '733', '041', '713', '431', '951', '956', '745', '783', '794']\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "atomic_tokens = [token for token in vocab if token.isdigit()]\n",
    "print(f\"Atomic tokens: {atomic_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 50257])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([50257, 2])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[10,12,13],[1,4,2]])\n",
    "print(model.wte.weight.T.shape) # torch.Size([768, 50257])\n",
    "output = model(input_tensor)\n",
    "print(output.last_hidden_state[:,-1,:].shape)  # torch.Size([2, 768])\n",
    "result = model.wte.weight @ output.last_hidden_state[:,-1,:].T\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m---> 36\u001b[0m losses \u001b[39m=\u001b[39m train(model, addition_dataloader, loss_fn, optimizer, num_epochs)\n\u001b[1;32m     38\u001b[0m \u001b[39m# Plot the loss curve\u001b[39;00m\n\u001b[1;32m     39\u001b[0m plt\u001b[39m.\u001b[39mplot(losses)\n",
      "Cell \u001b[0;32mIn[53], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m input_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([a, b], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m output \u001b[39m=\u001b[39m model(input_tensor)\n\u001b[0;32m---> 27\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, sum_ab)\n\u001b[1;32m     28\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/functional.py:3284\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, target):\n\u001b[1;32m   3281\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3282\u001b[0m         mse_loss, (\u001b[39minput\u001b[39m, target), \u001b[39minput\u001b[39m, target, size_average\u001b[39m=\u001b[39msize_average, reduce\u001b[39m=\u001b[39mreduce, reduction\u001b[39m=\u001b[39mreduction\n\u001b[1;32m   3283\u001b[0m     )\n\u001b[0;32m-> 3284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize()):\n\u001b[1;32m   3285\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   3286\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()),\n\u001b[1;32m   3289\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   3290\u001b[0m     )\n\u001b[1;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "class SumPredictor(nn.Module):\n",
    "    def __init__(self, gpt2_model):\n",
    "        super().__init__()\n",
    "        self.gpt2_model = gpt2_model\n",
    "\n",
    "    def forward(self, input_tensor: TensorType[\"batch\", \"sequence\"]):\n",
    "        output = self.gpt2_model(input_tensor)\n",
    "        return self.gpt2_model.wte.weight @ output.last_hidden_state[:, -1, :].T\n",
    "\n",
    "\n",
    "# Actually let's use Llama for this task because of the tokenization \n",
    "\n",
    "## Define the loss function\n",
    "#loss_fn = nn.MSELoss()\n",
    "#\n",
    "## Define the optimizer\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "#\n",
    "## Define the training function\n",
    "#def train(model, dataloader, loss_fn, optimizer, num_epochs):\n",
    "#    model.train()\n",
    "#    losses = []\n",
    "#    for epoch in tqdm(range(num_epochs)):\n",
    "#        epoch_loss = 0\n",
    "#        for a, b, sum_ab in dataloader:\n",
    "#            optimizer.zero_grad()\n",
    "#            input_tensor = torch.cat([a, b], dim=1)\n",
    "#            output = model(input_tensor)\n",
    "#            loss = loss_fn(output, sum_ab)\n",
    "#            loss.backward()\n",
    "#            optimizer.step()\n",
    "#            epoch_loss += loss.item()\n",
    "#        losses.append(epoch_loss / len(dataloader))\n",
    "#    return losses\n",
    "#\n",
    "## Train the model\n",
    "#num_epochs = 10\n",
    "#losses = train(model, addition_dataloader, loss_fn, optimizer, num_epochs)\n",
    "#\n",
    "## Plot the loss curve\n",
    "#plt.plot(losses)\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.title('Loss curve')\n",
    "#plt.show()\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
