{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12406\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "from torchtyping import TensorType\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, tokenizer, examples, max_length=50):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = examples\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question, answer = self.examples[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        labels = self.tokenizer.encode_plus(\n",
    "            answer,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': labels['input_ids'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_addition_validation(num_examples=100, max_number=100000000):\n",
    "    import random\n",
    "    examples = []\n",
    "    for _ in range(num_examples):\n",
    "        a = random.randint(0, max_number)\n",
    "        b = random.randint(0, max_number)\n",
    "        question = f\"{a}+{b}=\"\n",
    "        answer = str(a + b)\n",
    "        examples.append((question, answer))\n",
    "    return examples\n",
    "\n",
    "def generate_random_addition_training(num_examples=100, max_number=100000000):\n",
    "    import random\n",
    "    examples = []\n",
    "    for _ in range(num_examples):\n",
    "        a = random.randint(0, max_number)\n",
    "        b = random.randint(0, max_number)\n",
    "        question = f\"{a}+{b}=\"\n",
    "        answer = str(a + b)\n",
    "        examples.append((question, answer))\n",
    "    return examples\n",
    "\n",
    "def generate_ordered_addition_training(num_examples=100, max_number=100000000):\n",
    "    import random\n",
    "    examples = []\n",
    "    for _ in range(num_examples):\n",
    "        a = random.randint(0, max_number)\n",
    "        b = random.randint(0, max_number)\n",
    "        question = f\"{a}+{b}=\"\n",
    "        answer = str(a + b)\n",
    "        examples.append((question, answer))\n",
    "    # Sort the examples based on the sum of the numbers in the question\n",
    "    examples.sort(key=lambda x: sum(int(num) for num in x[0].split('+') if num.strip().isdigit()))\n",
    "    return examples\n",
    "\n",
    "def generate_reverse_ordered_addition_training(num_examples=100, max_number=100000000):\n",
    "    import random\n",
    "    examples = []\n",
    "    for _ in range(num_examples):\n",
    "        a = random.randint(0, max_number)\n",
    "        b = random.randint(0, max_number)\n",
    "        question = f\"{a}+{b}=\"\n",
    "        answer = str(a + b)\n",
    "        examples.append((question, answer))\n",
    "    # Sort the examples based on the sum of the numbers in the question in reverse order\n",
    "    examples.sort(key=lambda x: sum(int(num) for num in x[0].split('+') if num.strip().isdigit()), reverse=True)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12406\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "                                                 \n",
      "  3%|▎         | 51/1500 [00:06<05:44,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36602112650871277, 'eval_accuracy': 0.9246, 'eval_runtime': 1.0008, 'eval_samples_per_second': 99.917, 'eval_steps_per_second': 12.989, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "  7%|▋         | 101/1500 [00:10<04:33,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.344858318567276, 'eval_accuracy': 0.9248, 'eval_runtime': 0.7372, 'eval_samples_per_second': 135.649, 'eval_steps_per_second': 17.634, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|█         | 151/1500 [00:15<04:14,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3599613308906555, 'eval_accuracy': 0.9246, 'eval_runtime': 0.7199, 'eval_samples_per_second': 138.907, 'eval_steps_per_second': 18.058, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 13%|█▎        | 201/1500 [00:19<04:04,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37265831232070923, 'eval_accuracy': 0.9252, 'eval_runtime': 0.6879, 'eval_samples_per_second': 145.368, 'eval_steps_per_second': 18.898, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 17%|█▋        | 251/1500 [00:23<03:52,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3792695701122284, 'eval_accuracy': 0.9248, 'eval_runtime': 0.684, 'eval_samples_per_second': 146.197, 'eval_steps_per_second': 19.006, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 301/1500 [00:27<03:43,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3961324393749237, 'eval_accuracy': 0.9248, 'eval_runtime': 0.6804, 'eval_samples_per_second': 146.969, 'eval_steps_per_second': 19.106, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 351/1500 [00:32<03:53,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40267840027809143, 'eval_accuracy': 0.925, 'eval_runtime': 0.7869, 'eval_samples_per_second': 127.089, 'eval_steps_per_second': 16.522, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 27%|██▋       | 401/1500 [00:36<03:54,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41852977871894836, 'eval_accuracy': 0.9246, 'eval_runtime': 0.7941, 'eval_samples_per_second': 125.936, 'eval_steps_per_second': 16.372, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 30%|███       | 451/1500 [00:41<03:39,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45478156208992004, 'eval_accuracy': 0.9248, 'eval_runtime': 0.8083, 'eval_samples_per_second': 123.716, 'eval_steps_per_second': 16.083, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 500/1500 [00:45<01:14, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5543, 'learning_rate': 3.571428571428572e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 33%|███▎      | 501/1500 [00:47<07:31,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5226693153381348, 'eval_accuracy': 0.9248, 'eval_runtime': 0.7058, 'eval_samples_per_second': 141.688, 'eval_steps_per_second': 18.419, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 37%|███▋      | 551/1500 [00:52<03:04,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5360320806503296, 'eval_accuracy': 0.925, 'eval_runtime': 0.7111, 'eval_samples_per_second': 140.636, 'eval_steps_per_second': 18.283, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|████      | 601/1500 [00:56<02:42,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5643739700317383, 'eval_accuracy': 0.9246, 'eval_runtime': 0.6722, 'eval_samples_per_second': 148.764, 'eval_steps_per_second': 19.339, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 43%|████▎     | 651/1500 [01:00<02:35,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5904717445373535, 'eval_accuracy': 0.9246, 'eval_runtime': 0.6719, 'eval_samples_per_second': 148.841, 'eval_steps_per_second': 19.349, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 47%|████▋     | 701/1500 [01:05<02:24,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6216340065002441, 'eval_accuracy': 0.9252, 'eval_runtime': 0.6687, 'eval_samples_per_second': 149.553, 'eval_steps_per_second': 19.442, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 50%|█████     | 751/1500 [01:09<02:19,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6309906244277954, 'eval_accuracy': 0.9244, 'eval_runtime': 0.6977, 'eval_samples_per_second': 143.334, 'eval_steps_per_second': 18.633, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 53%|█████▎    | 801/1500 [01:13<02:07,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6367547512054443, 'eval_accuracy': 0.9256, 'eval_runtime': 0.6803, 'eval_samples_per_second': 146.987, 'eval_steps_per_second': 19.108, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 849/1500 [01:17<00:45, 14.33it/s]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    \"random\": generate_random_addition_training(),\n",
    "    \"ordered\": generate_ordered_addition_training(),\n",
    "    \"reverse_ordered\": generate_reverse_ordered_addition_training()\n",
    "}\n",
    "\n",
    "training_losses = {}\n",
    "\n",
    "# Initialize the GPT2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Add this line\n",
    "\n",
    "examples = generate_addition_validation()\n",
    "val_dataset = AdditionDataset(tokenizer, examples)\n",
    "\n",
    "for dataset_name, examples in datasets.items():\n",
    "\n",
    "    # Create a AdditionDataset instance for the validation set\n",
    "    train_dataset = AdditionDataset(tokenizer, examples)\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = logits.argmax(-1)\n",
    "        accuracy = (predictions == labels).mean().item()\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",  # output directory\n",
    "        num_train_epochs=30,  # total number of training epochs\n",
    "        per_device_train_batch_size=2,  # batch size per device during training\n",
    "        per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "        warmup_steps=100,  # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,  # strength of weight decay\n",
    "        logging_dir=\"./logs\",  # directory for storing logs\n",
    "        evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer_state = trainer.train()\n",
    "\n",
    "    # Store the training losses\n",
    "    training_losses[dataset_name] = [log.get('eval_loss', None) for log in trainer.state.log_history if 'eval_loss' in log]\n",
    "\n",
    "# Plot the training losses\n",
    "for dataset_name, losses in training_losses.items():\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs, losses, label=f'{dataset_name} training loss')\n",
    "\n",
    "for dataset_name, losses in training_losses.items():\n",
    "    print(f\"Final loss for {dataset_name}: {losses[-1]}\")\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
